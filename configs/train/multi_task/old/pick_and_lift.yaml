hydra:
  run:
    dir: ./train/train-pick_and_lift-${now:%Y.%m.%d-%H.%M.%S}

defaults:
  - ../../envs/base.yaml@_global_
  - ../../tasks/pick_and_lift.yaml@_global_/test
  - _self_

train_dataset:
  _target_: lib.demo_dataset.DemoDataset
  variations: [0]
  demos_config:
    amount: 200
    image_paths: True
    dataset_root: data
    task_name: pick_and_lift
    obs_config:
      _target_: rlbench.observation_config.ObservationConfig
    random_selection: False
    from_episode_number: 0
  action_mode:
    _target_: rlbench.action_modes.action_mode.MoveArmThenGripper
    arm_action_mode:
      _target_: rlbench.action_modes.arm_action_modes.EndEffectorPoseViaIK
      absolute_mode: False
    gripper_action_mode:
      _target_: rlbench.action_modes.gripper_action_modes.Discrete

train_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 128
  shuffle: True
  num_workers: 4
  persistent_workers: True

model:
  _target_: lib.bcz_model.BCZModel
  vision_encoder:
    _target_: lib.film_resnet.film_resnet18
    task_embed_dim: 768
  policy_decoder:
    _target_: lib.mlp_decoder.MLPDecoder

optimizer:
  _target_: torch.optim.Adam
  lr: 5e-3

train:
  n_steps: 100000
  log_interval: 10
  eval_interval: 2000
  save_interval: 2000
  device: cuda:1

test:
  _target_: test.test
  n_episodes: 10
  n_steps_per_episode: 200
  device: cuda:1
environment:
  headless: True

wandb:
  project: bcz-pytorch
  tags: [pick_and_lift, single_task, train]
