hydra:
  run:
    dir: ./train/train-${hydra:job.config_name}-${now:%Y.%m.%d-%H.%M.%S}

defaults:
  - ../../envs/base.yaml@_global_
  - ../../tasks/reach_target.yaml@_global_/test
  - _self_

train_dataset:
  _target_: lib.demo_dataset.DemoDataset
  variations: [0]
  demos_config:
    amount: 1000
    image_paths: True
    dataset_root: data_1000
    task_name: reach_target
    obs_config:
      _target_: rlbench.observation_config.ObservationConfig
      left_shoulder_camera:
        _target_: rlbench.observation_config.CameraConfig
        image_size:
          - 256
          - 256
        rgb: True
        depth: False
        mask: False
      right_shoulder_camera:
        _target_: rlbench.observation_config.CameraConfig
        image_size:
          - 256
          - 256
        rgb: True
        depth: False
        mask: False
      overhead_camera:
        _target_: rlbench.observation_config.CameraConfig
        image_size:
          - 256
          - 256
        rgb: True
        depth: False
        mask: False
      wrist_camera:
        _target_: rlbench.observation_config.CameraConfig
        image_size:
          - 256
          - 256
        rgb: True
        depth: False
        mask: False
      front_camera:
        _target_: rlbench.observation_config.CameraConfig
        image_size:
          - 256
          - 256
        rgb: True
        depth: False
        mask: False
    random_selection: False
    from_episode_number: 0
  action_mode:
    _target_: rlbench.action_modes.action_mode.MoveArmThenGripper
    arm_action_mode:
      _target_: rlbench.action_modes.arm_action_modes.EndEffectorPoseViaIK
      absolute_mode: False
    gripper_action_mode:
      _target_: rlbench.action_modes.gripper_action_modes.Discrete

train_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 128
  shuffle: True
  num_workers: 4
  persistent_workers: True

model:
  _target_: lib.bcz_model.BCZModel
  vision_encoder:
    _target_: lib.film_resnet.film_resnet18
    task_embed_dim: 768
  policy_decoder:
    _target_: lib.mlp_decoder.MLPDecoder

optimizer:
  _target_: torch.optim.Adam
  lr: 5e-3

train:
  n_steps: 100000
  log_interval: 10
  eval_interval: 2000
  save_interval: 2000
  device: cuda:0

test:
  _target_: test.test
  n_episodes: 10
  n_steps_per_episode: 100
  device: cuda:0
environment:
  headless: True

wandb:
  project: bcz-pytorch
  tags: [reach_target, single_task, train]
